---
---
@inproceedings{koreeda-etal-2016-neural,
    title = "Neural Attention Model for Classification of Sentences that Support Promoting/Suppressing Relationship",
    author = "Koreeda, Yuta  and
      Yanase, Toshihiko  and
      Yanai, Kohsuke  and
      Sato, Misa  and
      Niwa, Yoshiki",
    booktitle = "Proceedings of the Third Workshop on Argument Mining ({A}rg{M}ining2016)",
    month = aug,
    year = "2016",
    url = "https://aclanthology.org/W16-2809",
    doi = "10.18653/v1/W16-2809",
    pdf = "https://aclanthology.org/W16-2809.pdf",
    bibtex_show = "true"
}

@inproceedings{yanai-etal-2017-struap,
    title = "{S}tru{AP}: A Tool for Bundling Linguistic Trees through Structure-based Abstract Pattern",
    author = "Yanai, Kohsuke  and
      Sato, Misa  and
      Yanase, Toshihiko  and
      Kurotsuchi, Kenzo  and
      Koreeda, Yuta  and
      Niwa, Yoshiki",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = sep,
    year = "2017",
    url = "https://aclanthology.org/D17-2006",
    doi = "10.18653/v1/D17-2006",
    abstract = "We present a tool for developing tree structure patterns that makes it easy to define the relations among textual phrases and create a search index for these newly defined relations. By using the proposed tool, users develop tree structure patterns through abstracting syntax trees. The tool features (1) intuitive pattern syntax, (2) unique functions such as recursive call of patterns and use of lexicon dictionaries, and (3) whole workflow support for relation development and validation. We report the current implementation of the tool and its effectiveness.",
    pdf = "https://aclanthology.org/D17-2006.pdf",
    bibtex_show = "true"
}

@inproceedings{koreeda-etal-2017-bunji,
    title = "bunji at {S}em{E}val-2017 Task 3: Combination of Neural Similarity Features and Comment Plausibility Features",
    author = "Koreeda, Yuta  and
      Hashito, Takuya  and
      Niwa, Yoshiki  and
      Sato, Misa  and
      Yanase, Toshihiko  and
      Kurotsuchi, Kenzo  and
      Yanai, Kohsuke",
    booktitle = "Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017)",
    month = aug,
    year = "2017",
    url = "https://aclanthology.org/S17-2058",
    doi = "10.18653/v1/S17-2058",
    abstract = "This paper describes a text-ranking system developed by bunji team in SemEval-2017 Task 3: Community Question Answering, Subtask A and C. The goal of the task is to re-rank the comments in a question-and-answer forum such that useful comments for answering the question are ranked high. We proposed a method that combines neural similarity features and hand-crafted comment plausibility features, and we modeled inter-comments relationship using conditional random field. Our approach obtained the fifth place in the Subtask A and the second place in the Subtask C.",
    pdf = "https://aclanthology.org/S17-2058.pdf",
    bibtex_show = "true"
}

@inproceedings{ozaki-etal-2020-hitachi,
    title = "Hitachi at {MRP} 2020: Text-to-Graph-Notation Transducer",
    author = "Ozaki, Hiroaki  and
      Morio, Gaku  and
      Koreeda, Yuta  and
      Morishita, Terufumi  and
      Miyoshi, Toshinori",
    booktitle = "Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing",
    month = nov,
    year = "2020",
    url = "https://aclanthology.org/2020.conll-shared.4",
    doi = "10.18653/v1/2020.conll-shared.4",
    abstract = "This paper presents our proposed parser for the shared task on Meaning Representation Parsing (MRP 2020) at CoNLL, where participant systems were required to parse five types of graphs in different languages. We propose to unify these tasks as a text-to-graph-notation transduction in which we convert an input text into a graph notation. To this end, we designed a novel Plain Graph Notation (PGN) that handles various graphs universally. Then, our parser predicts a PGN-based sequence by leveraging Transformers and biaffine attentions. Notably, our parser can handle any PGN-formatted graphs with fewer framework-specific modifications. As a result, ensemble versions of the parser tied for 1st place in both cross-framework and cross-lingual tracks.",
    pdf = "https://aclanthology.org/K19-2011.pdf",
    bibtex_show = "true"
}

@inproceedings{morio-etal-2020-towards,
    title = "Towards Better Non-Tree Argument Mining: Proposition-Level Biaffine Parsing with Task-Specific Parameterization",
    author = "Morio, Gaku  and
      Ozaki, Hiroaki  and
      Morishita, Terufumi  and
      Koreeda, Yuta  and
      Yanai, Kohsuke",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL2020)",
    month = jul,
    year = "2020",
    url = "https://aclanthology.org/2020.acl-main.298",
    doi = "10.18653/v1/2020.acl-main.298",
    abstract = "State-of-the-art argument mining studies have advanced the techniques for predicting argument structures. However, the technology for capturing non-tree-structured arguments is still in its infancy. In this paper, we focus on non-tree argument mining with a neural model. We jointly predict proposition types and edges between propositions. Our proposed model incorporates (i) task-specific parameterization (TSP) that effectively encodes a sequence of propositions and (ii) a proposition-level biaffine attention (PLBA) that can predict a non-tree argument consisting of edges. Experimental results show that both TSP and PLBA boost edge prediction performance compared to baselines.",
    pdf = "https://aclanthology.org/2020.acl-main.298.pdf",
    video = "http://slideslive.com/38928683",
    bibtex_show = "true"
}

@inproceedings{ravikiran-etal-2020-hitachi,
    title = "Hitachi at {S}em{E}val-2020 Task 12: Offensive Language Identification with Noisy Labels Using Statistical Sampling and Post-Processing",
    author = "Ravikiran, Manikandan  and
      Muljibhai, Amin Ekant  and
      Miyoshi, Toshinori  and
      Ozaki, Hiroaki  and
      Koreeda, Yuta  and
      Masayuki, Sakata",
    booktitle = "Proceedings of the Fourteenth Workshop on Semantic Evaluation",
    month = dec,
    year = "2020",
    url = "https://aclanthology.org/2020.semeval-1.258",
    doi = "10.18653/v1/2020.semeval-1.258",
    abstract = "In this paper, we present our participation in SemEval-2020 Task-12 Subtask-A (English Language) which focuses on offensive language identification from noisy labels. To this end, we developed a hybrid system with the BERT classifier trained with tweets selected using Statistical Sampling Algorithm (SA) and Post-Processed (PP) using an offensive wordlist. Our developed system achieved 34th position with Macro-averaged F1-score (Macro-F1) of 0.90913 over both offensive and non-offensive classes. We further show comprehensive results and error analysis to assist future research in offensive language identification with noisy labels.",
    pdf = "https://aclanthology.org/2020.semeval-1.258.pdf",
    bibtex_show = "true"
}

@inproceedings{koreeda-manning-2021-contractnli-dataset,
    title = "{C}ontract{NLI}: A Dataset for Document-level Natural Language Inference for Contracts",
    author = "Koreeda, Yuta  and
      Manning, Christopher",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    url = "https://aclanthology.org/2021.findings-emnlp.164",
    doi = "10.18653/v1/2021.findings-emnlp.164",
    abstract = "Reviewing contracts is a time-consuming procedure that incurs large expenses to companies and social inequality to those who cannot afford it. In this work, we propose {``}document-level natural language inference (NLI) for contracts{''}, a novel, real-world application of NLI that addresses such problems. In this task, a system is given a set of hypotheses (such as {``}Some obligations of Agreement may survive termination.{''}) and a contract, and it is asked to classify whether each hypothesis is {``}entailed by{''}, {``}contradicting to{''} or {``}not mentioned by{''} (neutral to) the contract as well as identifying {``}evidence{''} for the decision as spans in the contract. We annotated and release the largest corpus to date consisting of 607 annotated contracts. We then show that existing models fail badly on our task and introduce a strong baseline, which (a) models evidence identification as multi-label classification over spans instead of trying to predict start and end tokens, and (b) employs more sophisticated context segmentation for dealing with long documents. We also show that linguistic characteristics of contracts, such as negations by exceptions, are contributing to the difficulty of this task and that there is much room for improvement.",
    video = "https://aclanthology.org/2021.findings-emnlp.164.mp4",
    pdf = "https://aclanthology.org/2021.findings-emnlp.164.pdf",
    selected = true,
    bibtex_show = "true"
}

@inproceedings{koreeda-manning-2021-capturing,
    title = "Capturing Logical Structure of Visually Structured Documents with Multimodal Transition Parser",
    author = "Koreeda, Yuta  and
      Manning, Christopher",
    booktitle = "Proceedings of the Natural Legal Language Processing Workshop 2021",
    month = nov,
    year = "2021",
    url = "https://aclanthology.org/2021.nllp-1.15",
    doi = "10.18653/v1/2021.nllp-1.15",
    abstract = "While many NLP pipelines assume raw, clean texts, many texts we encounter in the wild, including a vast majority of legal documents, are not so clean, with many of them being visually structured documents (VSDs) such as PDFs. Conventional preprocessing tools for VSDs mainly focused on word segmentation and coarse layout analysis, whereas fine-grained logical structure analysis (such as identifying paragraph boundaries and their hierarchies) of VSDs is underexplored. To that end, we proposed to formulate the task as prediction of {``}transition labels{''} between text fragments that maps the fragments to a tree, and developed a feature-based machine learning system that fuses visual, textual and semantic cues. Our system is easily customizable to different types of VSDs and it significantly outperformed baselines in identifying different structures in VSDs. For example, our system obtained a paragraph boundary detection F1 score of 0.953 which is significantly better than a popular PDF-to-text tool with an F1 score of 0.739.",
    pdf = "https://aclanthology.org/2021.nllp-1.15.pdf",
    bibtex_show = "true"
}

@inproceedings{tsunokake-etal-2023-hitachi,
    title = "Hitachi at {S}em{E}val-2023 Task 4: Exploring Various Task Formulations Reveals the Importance of Description Texts on Human Values",
    author = "Tsunokake, Masaya  and
      Yamaguchi, Atsuki  and
      Koreeda, Yuta  and
      Ozaki, Hiroaki  and
      Sogawa, Yasuhiro",
    booktitle = "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    month = jul,
    year = "2023",
    url = "https://aclanthology.org/2023.semeval-1.240",
    doi = "10.18653/v1/2023.semeval-1.240",
    abstract = "This paper describes our participation in SemEval-2023 Task 4, ValueEval: Identification of Human Values behind Arguments. The aim of this task is to identify whether or not an input text supports each of the 20 pre-defined human values. Previous work on human value detection has shown the effectiveness of a sequence classification approach using BERT. However, little is known about what type of task formulation is suitable for the task. To this end, this paper explores various task formulations, including sequence classification, question answering, and question answering with chain-of-thought prompting and evaluates their performances on the shared task dataset. Experiments show that a zero-shot approach is not as effective as other methods, and there is no one approach that is optimal in every scenario. Our analysis also reveals that utilizing the descriptions of human values can help to improve performance.",
    video = "https://aclanthology.org/2023.semeval-1.240.mp4",
    pdf = "https://aclanthology.org/2023.semeval-1.240.pdf",
    bibtex_show = "true"
}

@inproceedings{koreeda-etal-2023-hitachi,
    title = "Hitachi at {S}em{E}val-2023 Task 3: Exploring Cross-lingual Multi-task Strategies for Genre and Framing Detection in Online News",
    author = "Koreeda, Yuta  and
      Yokote, Ken-ichi  and
      Ozaki, Hiroaki  and
      Yamaguchi, Atsuki  and
      Tsunokake, Masaya  and
      Sogawa, Yasuhiro",
    booktitle = "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    month = jul,
    year = "2023",
    url = "https://aclanthology.org/2023.semeval-1.237",
    doi = "10.18653/v1/2023.semeval-1.237",
    abstract = "This paper explains the participation of team Hitachi to SemEval-2023 Task 3 {``}Detecting the genre, the framing, and the persuasion techniques in online news in a multi-lingual setup.{''} Based on the multilingual, multi-task nature of the task and the low-resource setting, we investigated different cross-lingual and multi-task strategies for training the pretrained language models. Through extensive experiments, we found that (a) cross-lingual/multi-task training, and (b) collecting an external balanced dataset, can benefit the genre and framing detection. We constructed ensemble models from the results and achieved the highest macro-averaged F1 scores in Italian and Russian genre categorization subtasks.",
    video = "https://aclanthology.org/2023.semeval-1.237.mp4",
    pdf = "https://aclanthology.org/2023.semeval-1.237.pdf",
    bibtex_show = "true"
}

@inproceedings{koreeda-etal-2023-larch,
    author = "Koreeda, Yuta and Morishita, Terufumi and Imaichi, Osamu and Sogawa, Yasuhiro",
    title = "LARCH: Large Language Model-based Automatic Readme Creation with Heuristics",
    year = "2023",
    isbn = "9798400701245",
    url = "https://doi.org/10.1145/3583780.3614744",
    doi = "10.1145/3583780.3614744",
    abstract = "Writing a readme is a crucial aspect of software development as it plays a vital role in managing and reusing program code. Though it is a pain point for many developers, automatically creating one remains a challenge even with the recent advancements in large language models (LLMs), because it requires generating an abstract description from thousands of lines of code. In this demo paper, we show that LLMs are capable of generating a coherent and factually correct readmes if we can identify a code fragment that is representative of the repository. Building upon this finding, we developed LARCH (LLM-based Automatic Readme Creation with Heuristics) which leverages representative code identification with heuristics and weak supervision. Through human and automated evaluations, we illustrate that LARCH can generate coherent and factually correct readmes in the majority of cases, outperforming a baseline that does not rely on representative code identification. We have made LARCH open-source and provided a cross-platform Visual Studio Code interface and command-line interface, accessible at https://github.com/hitachi-nlp/larch. A demo video showcasing LARCH's capabilities is available at https://youtu.be/ZUKkh5ED-O4.",
    booktitle = "Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM'23)",
    pdf = "https://dl.acm.org/doi/pdf/10.1145/3583780.3614744",
    video = "https://youtu.be/ZUKkh5ED-O4",
    selected = "true",
    bibtex_show = "true"
}


@inproceedings{morishita-etal-2024-chicot,
    title = "CHICOT: A Developer-Assistance Toolkit for Code Search with High-Level Contextual Information",
    url = "https://ojs.aaai.org/index.php/AAAI/article/view/30575",
    DOI = "10.1609/aaai.v38i21.30575",
    abstract = "We propose a source code search system named CHICOT (Code search with HIgh level COnText) to assist developers in reusing existing code. While previous studies have examined code search on the basis of code-level, fine-grained specifications such as functionality, logic, or implementation, CHICOT addresses a unique mission: code search with high-level contextual information, such as the purpose or domain of a developer’s project. It achieves this feature by first extracting the context information from codebases and then considering this context during the search. It provides a VSCode plugin for daily coding assistance, and the built-in crawler ensures up-to-date code suggestions. The case study attests to the utility of CHICOT in real-world scenarios.",
    booktitle = "Proceedings of the AAAI Conference on Artificial Intelligence",
    author = "Morishita, Terufumi and Koreeda, Yuta and Yamaguchi, Atsuki and Morio, Gaku and Imaichi, Osamu and Sogawa, Yasuhiro",
    year = "2024",
    month = mar,
    pdf = "https://ojs.aaai.org/index.php/AAAI/article/view/30575/32737},
    bibtex_show = "true"
}

@article{
   liang-etal-2023-holistic,
   title = "Holistic Evaluation of Language Models",
   author = "Percy Liang and Rishi Bommasani and Tony Lee and Dimitris Tsipras and Dilara Soylu and Michihiro Yasunaga and Yian Zhang and Deepak Narayanan and Yuhuai Wu and Ananya Kumar and Benjamin Newman and Binhang Yuan and Bobby Yan and Ce Zhang and Christian Alexander Cosgrove and Christopher D Manning and Christopher Re and Diana Acosta-Navas and Drew Arad Hudson and Eric Zelikman and Esin Durmus and Faisal Ladhak and Frieda Rong and Hongyu Ren and Huaxiu Yao and Jue WANG and Keshav Santhanam and Laurel Orr and Lucia Zheng and Mert Yuksekgonul and Mirac Suzgun and Nathan Kim and Neel Guha and Niladri S. Chatterji and Omar Khattab and Peter Henderson and Qian Huang and Ryan Andrew Chi and Sang Michael Xie and Shibani Santurkar and Surya Ganguli and Tatsunori Hashimoto and Thomas Icard and Tianyi Zhang and Vishrav Chaudhary and William Wang and Xuechen Li and Yifan Mai and Yuhui Zhang and Yuta Koreeda",
   journal = "Transactions on Machine Learning Research",
   issn = "2835-8856",
   year = "2023",
   url = "https://openreview.net/forum?id=iO4LZibEqW",
   abstract = "Language models (LMs) are becoming the foundation for almost all major language technologies, but their capabilities, limitations, and risks are not well understood. We present Holistic Evaluation of Language Models (HELM) to improve the transparency of language models. First, we taxonomize the vast space of potential scenarios (i.e. use cases) and metrics (i.e. desiderata) that are of interest for LMs. Then we select a broad subset based on coverage and feasibility, noting what’s missing or underrepresented (e.g. question answering for neglected English dialects, metrics for trustworthiness). Second, we adopt a multi-metric approach: We measure 7 metrics (accuracy, calibration, robustness, fairness, bias, toxicity, and efficiency) for each of 16 core scenarios to the extent possible (87.5\% of the time), ensuring that metrics beyond accuracy don’t fall to the wayside, and that trade-offs across models and metrics are clearly exposed. We also perform 7 targeted evaluations, based on 26 targeted scenarios, to more deeply analyze specific aspects (e.g. knowledge, reasoning, memorization/copyright, disinformation). Third, we conduct a large-scale evaluation of 30 prominent language models (spanning open, limited-access, and closed models) on all 42 scenarios, including 21 scenarios that were not previously used in mainstream LM evaluation. Prior to HELM, models on average were evaluated on just 17.9\% of the core HELM scenarios, with some prominent models not sharing a single scenario in common. We improve this to 96.0\%: now all 30 models have been densely benchmarked on a set of core scenarios and metrics under standardized conditions. Our evaluation surfaces 25 top-level findings concerning the interplay between different scenarios, metrics, and models. For full transparency, we release all raw model prompts and completions publicly for further analysis, as well as a general modular toolkit for easily adding new scenarios, models, metrics, and prompting strategies. We intend for HELM to be a living benchmark for the community, continuously updated with new scenarios, metrics, and models.",
   pdf = "https://openreview.net/pdf?id=iO4LZibEqW",
   website = "https://crfm.stanford.edu/helm/",
   tags = "Journal",
   bibtex_show = "true"
}

@article{koreeda-etal-2015-development,
  author = {Koreeda, Yuta
    and Obata, Satoshi
    and Nishio, Yuya
    and Miura, Satoshi
    and Kobayashi, Yo
    and Kawamura, Kazuya
    and Souzaki, Ryota
    and Ieiri, Satoshi
    and Hashizume, Makoto
    and Fujie, Masakatsu G.},
  title = "Development and testing of an endoscopic pseudo-viewpoint alternating system",
  journal = "International Journal of Computer Assisted Radiology and Surgery",
  year = "2015",
  month = may,
  volume = "10",
  number = "5",
  pages = "619-628",
  abstract = "An endoscopic system is needed that presents informative images irrespective of the surgical situation and the number of degrees of freedom in endoscopic manipulation. This goal may be achieved with a virtual reality view for a region of interest from an arbitrary viewpoint. An endoscopic pseudo-viewpoint alternation system for this purpose was developed and tested.",
  issn = "1861-6429",
  publisher = "Springer",
  doi = "10.1007/s11548-014-1083-z",
  url = "https://doi.org/10.1007/s11548-014-1083-z",
  tags = "Journal",
  pdf = "https://link.springer.com/content/pdf/10.1007/s11548-014-1083-z.pdf",
  bibtex_show = "true"
}

@article{koreeda-etal-2016-virtually,
  author={Koreeda, Yuta
    and Kobayashi, Yo
    and Ieiri, Satoshi
    and Nishio, Yuya
    and Kawamura, Kazuya
    and Obata, Satoshi
    and Souzaki, Ryota
    and Hashizume, Makoto
    and Fujie, Masakatsu G.},
  title = "Virtually transparent surgical instruments in endoscopic surgery with augmentation of obscured regions",
  journal = "International Journal of Computer Assisted Radiology and Surgery",
  year = "2016",
  month = "Oct",
  volume = "11",
  number = "10",
  pages = "1927-1936",
  publisher = "Springer",
  abstract = "We developed and evaluated a visual compensation system that allows surgeons to visualize obscured regions in real time, such that the surgical instrument appears virtually transparent.",
  issn = "1861-6429",
  doi = "10.1007/s11548-016-1384-5",
  url = "https://doi.org/10.1007/s11548-016-1384-5",
  tags = "Journal",
  pdf = "https://link.springer.com/content/pdf/10.1007/s11548-014-1083-z.pdf",
  bibtex_show = "true"
}

@inproceedings{wang-etal-2020-split,
  author = "Wang, Mengru
    and Ozaki, Hiroaki
    and Koreeda, Yuta
    and Yanai, Kohsuke",
  title = "Split First and Then Rephrase: Hierarchical Generation for Sentence Simplification",
  booktitle = "Proceedings of International Conference of the Pacific Association for Computational Linguistics (PACLING2019)",
  year = "2020",
  abstract = "Split-and-rephrase is a strategy known to be used when humans need to break down a complex sentence into a meaning preserving sequence of shorter ones. Recent work proposed to model split-and-rephrase as a supervised sequence generation problem. However, different from other types of sequence generations, the task of split-and-rephrase inevitably introduces overlaps across splits to compensate for the missing context caused by separating a sentence. Serving as the baseline of this task, the vanilla SEQ2SEQ model usually suffers from inappropriate duplication because of the lack of a mechanism to plan how the source sentence should be split into shorter units. This work demonstrates that the problem of inappropriate duplication can be tackled by explicitly modeling the hierarchy within split-and-rephrase: Our model first introduces a separator network capable of selecting semantic components from the source sentence to form a representation for each split. Then, a decoder generates each split on the basis of its representation. Analyses demonstrate that with the aid of the separator, a model can effectively learn attention to avoid duplication and detect clues for splitting a sentence. Experimental results on the WikiSplit corpus show that our model outperforms the non-hierarchical SEQ2SEQ model by 1.4 points in terms of duplication rate and by 0.3 points in terms of coverage rate.",
  isbn = "978-981-15-6168-9",
  url = "https://link.springer.com/chapter/10.1007/978-981-15-6168-9_2",
  tags = "Award",
  award = "The 16th International Conference of the Pacific Association for Computational Linguistics (PACLING) Best Paper Award"
}

@inproceedings{sato-etal-2017-debating,
  title = "Debating AI: Argument Generation by Retrieving Sentences from the Minutes of the Diet",
  author = {Sato, Misa
    and Yanai, Kohsuke
    and Yanase, Toshihiko
    and Koreeda, Yuta
    and Niwa, Yoshiki
  },
  booktitle = "Proceedings of the 31st Annual Conference of the Japanese Society for Artificial Intelligence",
  month = may,
  year = 2017,
  doi = "10.11517/pjsai.JSAI2017.0_4Q19in2",
  url = "https://www.jstage.jst.go.jp/article/pjsai/JSAI2017/0/JSAI2017_4Q19in2/_article/-char/ja/",
  abstract = {We will demonstrate a counterargument generation system in debating, which aims to utilize newswire articles for decision-making support. Users can specify a claim such as “We should legalize casinos because they promote economy.” and then the system outputs counterargument scripts against the claim. },
  pdf = "https://www.jstage.jst.go.jp/article/pjsai/JSAI2017/0/JSAI2017_4Q19in2/_pdf/-char/ja",
  ja_entry = "佐藤美沙, 柳井孝介, 柳瀬利彦, 是枝祐太, 丹羽芳樹. 2017, 国会会議録を用いたディベート人工知能による意見生成. 2017年度人工知能学会全国大会論文集.",
  tags = "Award, Japanese, Domestic"
}

@article{sato-etal-2016-textual,
  title = "Textual Supportiveness Recognition Based on Combinations of Syntax Features for Automated Argument Generation",
  author = {Sato, Misa
    and Yanai, Kohsuke
    and Yanase, Toshihiko
    and Miyoshi, Toshinori
    and Koreeda, Yuta
    and Niwa, Yoshiki
  },
  journal = "Transactions of the Japanese Society for Artificial Intelligence",
  volume = "31",
  number = "6",
  pages = "AI30-L_1-12",
  year = "2016",
  doi = "10.1527/tjsai.AI30-L",
  abstract = {This paper describes a technique to recognize "supportiveness" of a given text for an argument topic object and a value. Given an argument topic object (o), a value (v), and a text fragment (t), supportiveness refers to whether t supports a hypothesis "o promotes/suppresses v" or not. For example, with "o: casino" and "v: employment", then a text "The casinos in Mississippi have created 35,000 jobs." should support a hypothesis "o promotes v". This technique enables to automatically collect texts representing reasons and counterexamples for some hypothesis that humans build up (e.g. "casino promotes employment"), combined with text search. Because the difference from relation extraction is polarity of relations, proposed method utilizes multiplifications based on local syntax structures, extending reversing hypothesis in sentiment analysis. We propose feature combinations consisting of "primary features" and "secondary features" for supportiveness recognition. "Primary features" represent local syntax structures around a given target or a given value. "Secondary features" represent global syntax structures generated by combining the primary features. The proposed method calculates weighted sum of secondary features to recognize promoting/suppressing supportiveness. The experiments showed that our method outperforms a Bag-of-Words baseline and a conventional relation extraction method.},
  ja_entry = "佐藤美沙, 柳井孝介, 柳瀬利彦, 三好利昇, 是枝祐太, 丹羽芳樹. 2016. 意見文章自動生成のための組合せ構文特徴を用いたサポート性推定. 人工知能学会論文誌, 31:6, pages AI30-L_1-12.",
  tags = "Journal, Japanese"
}

@inproceedings{morio-etal-2021-i-parser,
  title = "i-{P}arser: {I}nteractive Parser Development Kit for Natural Language Processing",  
  author = {Morio, Gaku
    and Ozaki, Hiroaki
    and Koreeda, Yuta
    and Morishita, Terufumi
    and Miyoshi, Toshinori
  },
  month = jan,
  year = "2021",
  booktitle = "Proceedings of the AAAI Conference on Artificial Intelligence (AAAI-21)",
  abstract = {This demonstration paper presents i-Parser, a novel development kit that produces high-performance semantic parsers. i-Parser converts training graphs into sequences written in a context-free language, then our proposed model learns to generate the sequences. With interactive configuration and visualization, users can easily build their own parsers. Benchmark results of i-Parser showed high performances of various parsing tasks in natural language processing.},
  doi = "10.1609/aaai.v35i18.18021",
  url = "https://aaai.org/papers/16091-i-parser-interactive-parser-development-kit-for-natural-language-processing/",
  pdf = "https://cdn.aaai.org/ojs/18021/18021-13-21515-1-2-20210518.pdf"  
}

@article{nakayama-etal-2015-estimation,
  title = "Estimation technique of the destined target with gesture recognition for the development of in-car interface of automated driving vehicle",
  author = {Nakayama, Masayuki
    and Miura, Satoshi
    and Kawano, Shinya
    and Koreeda, Yuta
    and Yamamoto, Akihiro
    and Fukumoto, Ryota
    and Sakuma, Tsuyoshi
    and Nakashima, Tsuyoshi
    and Kobayashi, Yo
    and Fujie, Masakatsu G.
  },
  journal = "Transactions of the JSME",
  volume = "81",
  number = "832",
  pages = "15-00088-15-00088",
  month = dec,
  year = "2015",
  doi = "10.1299/transjsme.15-00088",
  abstract = {In recent years, development of the automated driving system is aggressively promoted for the purpose of reducing burden of drivers and for the enhanced safety. Transferring the intention of the driver to the automobile control, such as to stop on the way or to change destinations, is essential even if a direct control from the driver is no longer necessary. Therefore, an in-car interface to conduct intention of the driver promptly and accurately to the automobile control is needed. In this paper, we proposed an interface which recognizes the intended target of the driver using gestures and speech recognition. The speech recognition technology was previously developed. Hence, we developed an interface to recognize the direction in which the driver is pointing toward from the gesture. We hypothesize that we can estimate the direction in which the driver is pointing toward from the fingertip and eye position. Verification using three-dimensional motion analysis system showed that it is possible to recognize the direction of the object with a maximum error of 5.5° and an average error of 1.2°. After verifying the hypothesis, a position measurement device that integrates Leap Motion® and KINECT®, the non-contact sensor, was developed to recognize gestures of the driver in the automobiles. The maximum error of the angle recognition in accordance with the present device was 16.1°. However, the value of the error exists only in a certain interval. For this reason, by taking into account the movement of the eye position, and provide adequate tuning for each driver, proposed interface is sufficiently
usable.},
  url = "https://www.jstage.jst.go.jp/article/transjsme/81/832/81_15-00088/_article/-char/ja",
  pdf = "https://www.jstage.jst.go.jp/article/transjsme/81/832/81_15-00088/_pdf/-char/ja",
  ja_entry = "中山正之, 三浦智, 河野信哉, 是枝祐太, 山本晃裕, 福本亮太, 佐久間壮, 中島康貴, 小林洋, 藤江正克. 2015. 自動運転のインターフェース構築を目的とした視点と指先位置の測定による指示方向推定手法の構築. 日本機械学会論文集, 81:832, pages 15-00088-15-00088.",
  tags = "Journal, Japanese"
}

@inproceedings{tsunokake-etal-2023-predicting,
  title = "Predicting Order Timing Utilizing Temporal Expressions in Sales Activity Reports",
  author = {Tsunokake, Masaya
    and Koreeda, Yuta
    and Homma, Ken
    and Inoue, Teppei
    and Niwa, Yuhei
  },
  booktitle = "Proceedings of the 37th Annual Conference of the Japanese Society for Artificial Intelligence",
  month = may,
  year = "2023",
  doi = "10.11517/pjsai.JSAI2023.0_4Xin110",
  url = "https://www.jstage.jst.go.jp/article/pjsai/JSAI2023/0/JSAI2023_4Xin110/_article/-char/ja/",
  pdf = "https://www.jstage.jst.go.jp/article/pjsai/JSAI2023/0/JSAI2023_4Xin110/_pdf/-char/ja",
  ja_entry = "角掛正弥, 是枝祐太, 本間健, 井上鉄平, 丹羽雄平. 2023. 営業報告書内の時間情報表現を手掛かりとした受注時期の予測. 人工知能学会全国大会論文集.",
  tags = "Domestic, Japanese"
}

@article{miura-etal-2022-virtual,
  title = "Virtual Shadow Drawing System Using Augmented Reality for Laparoscopic Surgery",
  author = "Satoshi Miura and Masaki Seki and Yuta Koreeda and Yang Cao and Kazuya Kawamura and Yo Kobayashi and Masakatsu G. Fujie and Tomoyuki Miyashita",
  journal = "Advanced Biomedical Engineering",
  volume = "11",
  pages = "87-97",
  month = apr,
  year = "2022",
  doi = "10.14326/abe.11.87",
  abstract = {Laparoscopic surgery holds great promise in medicine but remains challenging for surgeons because it is difficult to perceive depth while suturing. In addition to binocular parallax, such as three-dimensional vision, shadow is essential for depth perception. This paper presents an augmented reality system that draws virtual shadows to aid depth perception. On the visual display, the system generates shadows that mimic actual shadows by estimating shadow positions using image processing. The distance and angle between the forceps tip and the surface were estimated to evaluate the accuracy of the system. To validate the usefulness of this system in surgical applications, novices performed suturing tasks with and without the augmented reality system. The system error and delay were sufficiently small, and the generated shadows were similar to actual shadows. Furthermore, the suturing error decreased significantly when the augmented reality system was used. The shadow-drawing system developed in this study may help surgeons perceive depth during laparoscopic surgery.},
  url = "https://doi.org/10.14326/abe.11.87",
  pdf = "https://www.jstage.jst.go.jp/article/abe/11/0/11_11_87/_pdf/-char/ja",
  tags = "Journal"
}

@inproceedings{miura-etal-2020-evaluation,
  author = "Miura, Satoshi and Seki, Masaki and Koreeda, Yuta and Cao, Yang and Kawamura, Kazuya and Kobayashi, Yo and Fujie, Masakatsu G. and Miyashita, Tomoyuki",
  booktitle = "2020 8th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob)",
  title = "Evaluation of Virtual Shadow’s Direction in Laparoscopic Surgery",
  month = nov,
  year = "2020",
  doi = "10.1109/BioRob49111.2020.9224346",
  url = "https://doi.org/10.1109/BioRob49111.2020.9224346",
  abstract = {Laparoscopic surgery can realize minimal invasive surgery. However, it's difficult for surgeon to recognize the depth during suturing. Binocular endoscope helps surgeons to recognize the depth, but surgeons do not understand the circumstance by equipping with head mounted display. Since shadow helps surgeon to recognize the depth, in this paper, we developed the virtual shadow drawing system. The system shows shadow like actual by the estimation of the forceps position, surface shape and shadow's position. We tested the accuracy of the system by evaluating the estimated distance and angle between the forceps and the surface. The error and delay were enough small to draw shadow like actual. Furthermore, participants performed the suturing task while looking at the shadow. The experiment was carried out in a variety of the shadow's direction. As result, the suturing error's mean and variance value was the least at the 270 deg. In conclusion, the appropriate shadow would be vertical to the wounds.}
}

@article{koreeda-etal-2019-a,
  title = "A Joint Neural Model for Patent Classification and Rationale Identification",
  author = "Yuta Koreeda and Hisao Mase and Kohsuke Yanai",
  journal = "Transactions of the Japanese Society for Artificial Intelligence",
  volume = "34",
  number = "5",
  pages = "F-IC1_1-11",
  year = "2019",
  doi = "10.1527/tjsai.F-IC1",
  abstract = {Japan Patent Office manually annotates submitted patents with F-terms (a patent classification scheme consisting of more than 300,000 labels) to aid search for prior patent applications. Keeping up the quality of F-term annotation is critical to patentability assessments, thus there is a demand for an automatic way to assist F-term annotation. One potential solution is to point out annotation mistakes by utilizing machine learning-based classification. However, the annotators cannot validate the predicted corrections because conventional classification methods do not give the rationales behind the corrections. Thus, the annotators may only adopt all or no corrections. The goal of this study was to assist F-term annotation by presenting annotators with corrections on the F-term annotation and the rationales behind the corrections. We proposed a joint neural model for F-term annotation and rationale identification. The proposed method incorporates a large portion of data annotated only with F-terms and a small portion of data annotated with rationales. It was first trained for F-term annotation, and then fine-tuned using the ground-truth rationales to discriminate rationales from non-rationales. We evaluated the proposed method on multiple F-terms from different technical domains. The proposed method outperformed baseline methods in terms of the rationale identification, implying that incorporating rationales in training is particularly useful in identifying rationales.},
  url = "https://doi.org/10.1527/tjsai.F-IC1",
  pdf = "https://www.jstage.jst.go.jp/article/tjsai/34/5/34_F-IC1/_pdf/-char/en",
  ja_entry = "是枝祐太, 間瀬久雄, 柳井孝介. 2019. 特許文献に対する分類付与と付与根拠箇所推定のための統合深層学習. 人工知能学会論文誌, 34:5, pages F-IC1_1-11.",
  tags = "Journal, Japanese"
}