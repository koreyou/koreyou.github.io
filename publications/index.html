<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Yuta Koreeda </title> <meta name="author" content="Yuta Koreeda"> <meta name="description" content=""> <meta name="keywords" content="academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E6%98%AF&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://koreyou.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Yuta</span> Koreeda </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="tsunokake-etal-2023-hitachi" class="col-sm-8"> <div class="title">Hitachi at SemEval-2023 Task 4: Exploring Various Task Formulations Reveals the Importance of Description Texts on Human Values</div> <div class="author"> Masaya Tsunokake, Atsuki Yamaguchi, <em>Yuta Koreeda</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Hiroaki Ozaki, Yasuhiro Sogawa' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)</em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.18653/v1/2023.semeval-1.240" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2023.semeval-1.240.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://aclanthology.org/2023.semeval-1.240.mp4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>This paper describes our participation in SemEval-2023 Task 4, ValueEval: Identification of Human Values behind Arguments. The aim of this task is to identify whether or not an input text supports each of the 20 pre-defined human values. Previous work on human value detection has shown the effectiveness of a sequence classification approach using BERT. However, little is known about what type of task formulation is suitable for the task. To this end, this paper explores various task formulations, including sequence classification, question answering, and question answering with chain-of-thought prompting and evaluates their performances on the shared task dataset. Experiments show that a zero-shot approach is not as effective as other methods, and there is no one approach that is optimal in every scenario. Our analysis also reveals that utilizing the descriptions of human values can help to improve performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">tsunokake-etal-2023-hitachi</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hitachi at {S}em{E}val-2023 Task 4: Exploring Various Task Formulations Reveals the Importance of Description Texts on Human Values}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tsunokake, Masaya and Yamaguchi, Atsuki and Koreeda, Yuta and Ozaki, Hiroaki and Sogawa, Yasuhiro}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2023.semeval-1.240}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2023.semeval-1.240}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="koreeda-etal-2023-hitachi" class="col-sm-8"> <div class="title">Hitachi at SemEval-2023 Task 3: Exploring Cross-lingual Multi-task Strategies for Genre and Framing Detection in Online News</div> <div class="author"> <em>Yuta Koreeda</em>, Ken-ichi Yokote, Hiroaki Ozaki, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Atsuki Yamaguchi, Masaya Tsunokake, Yasuhiro Sogawa' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)</em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.18653/v1/2023.semeval-1.237" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2023.semeval-1.237.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://aclanthology.org/2023.semeval-1.237.mp4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>This paper explains the participation of team Hitachi to SemEval-2023 Task 3 “Detecting the genre, the framing, and the persuasion techniques in online news in a multi-lingual setup.” Based on the multilingual, multi-task nature of the task and the low-resource setting, we investigated different cross-lingual and multi-task strategies for training the pretrained language models. Through extensive experiments, we found that (a) cross-lingual/multi-task training, and (b) collecting an external balanced dataset, can benefit the genre and framing detection. We constructed ensemble models from the results and achieved the highest macro-averaged F1 scores in Italian and Russian genre categorization subtasks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">koreeda-etal-2023-hitachi</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hitachi at {S}em{E}val-2023 Task 3: Exploring Cross-lingual Multi-task Strategies for Genre and Framing Detection in Online News}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Koreeda, Yuta and Yokote, Ken-ichi and Ozaki, Hiroaki and Yamaguchi, Atsuki and Tsunokake, Masaya and Sogawa, Yasuhiro}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2023.semeval-1.237}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2023.semeval-1.237}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="koreeda-etal-2023-larch" class="col-sm-8"> <div class="title">LARCH: Large Language Model-based Automatic Readme Creation with Heuristics</div> <div class="author"> <em>Yuta Koreeda</em>, Terufumi Morishita, Osamu Imaichi, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Yasuhiro Sogawa' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM’23)</em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3583780.3614744" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/pdf/10.1145/3583780.3614744" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://youtu.be/ZUKkh5ED-O4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Writing a readme is a crucial aspect of software development as it plays a vital role in managing and reusing program code. Though it is a pain point for many developers, automatically creating one remains a challenge even with the recent advancements in large language models (LLMs), because it requires generating an abstract description from thousands of lines of code. In this demo paper, we show that LLMs are capable of generating a coherent and factually correct readmes if we can identify a code fragment that is representative of the repository. Building upon this finding, we developed LARCH (LLM-based Automatic Readme Creation with Heuristics) which leverages representative code identification with heuristics and weak supervision. Through human and automated evaluations, we illustrate that LARCH can generate coherent and factually correct readmes in the majority of cases, outperforming a baseline that does not rely on representative code identification. We have made LARCH open-source and provided a cross-platform Visual Studio Code interface and command-line interface, accessible at https://github.com/hitachi-nlp/larch. A demo video showcasing LARCH’s capabilities is available at https://youtu.be/ZUKkh5ED-O4.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">koreeda-etal-2023-larch</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Koreeda, Yuta and Morishita, Terufumi and Imaichi, Osamu and Sogawa, Yasuhiro}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{LARCH: Large Language Model-based Automatic Readme Creation with Heuristics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400701245}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3583780.3614744}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3583780.3614744}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM'23)}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="liang-etal-2023-holistic" class="col-sm-8"> <div class="title">Holistic Evaluation of Language Models</div> <div class="author"> Percy Liang, Rishi Bommasani, Tony Lee, and <span class="more-authors" title="click to view 47 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '47 more authors' ? 'Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang, Christian Alexander Cosgrove, Christopher D Manning, Christopher Re, Diana Acosta-Navas, Drew Arad Hudson, Eric Zelikman, Esin Durmus, Faisal Ladhak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue WANG, Keshav Santhanam, Laurel Orr, Lucia Zheng, Mert Yuksekgonul, Mirac Suzgun, Nathan Kim, Neel Guha, Niladri S. Chatterji, Omar Khattab, Peter Henderson, Qian Huang, Ryan Andrew Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli, Tatsunori Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang, Xuechen Li, Yifan Mai, Yuhui Zhang, Yuta Koreeda' : '47 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">47 more authors</span> </div> <div class="periodical"> <em>Transactions on Machine Learning Research</em>, Jul 2023 </div> <div class="periodical"> </div> <span class="rounded-pill badge publications-tag"> Award </span> <span class="rounded-pill badge publications-tag"> Journal </span> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Awarded</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/pdf?id=iO4LZibEqW" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://crfm.stanford.edu/helm/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>2024 TMLR Outstanding Certification</p> </div> <div class="abstract hidden"> <p>Language models (LMs) are becoming the foundation for almost all major language technologies, but their capabilities, limitations, and risks are not well understood. We present Holistic Evaluation of Language Models (HELM) to improve the transparency of language models. First, we taxonomize the vast space of potential scenarios (i.e. use cases) and metrics (i.e. desiderata) that are of interest for LMs. Then we select a broad subset based on coverage and feasibility, noting what’s missing or underrepresented (e.g. question answering for neglected English dialects, metrics for trustworthiness). Second, we adopt a multi-metric approach: We measure 7 metrics (accuracy, calibration, robustness, fairness, bias, toxicity, and efficiency) for each of 16 core scenarios to the extent possible (87.5% of the time), ensuring that metrics beyond accuracy don’t fall to the wayside, and that trade-offs across models and metrics are clearly exposed. We also perform 7 targeted evaluations, based on 26 targeted scenarios, to more deeply analyze specific aspects (e.g. knowledge, reasoning, memorization/copyright, disinformation). Third, we conduct a large-scale evaluation of 30 prominent language models (spanning open, limited-access, and closed models) on all 42 scenarios, including 21 scenarios that were not previously used in mainstream LM evaluation. Prior to HELM, models on average were evaluated on just 17.9% of the core HELM scenarios, with some prominent models not sharing a single scenario in common. We improve this to 96.0%: now all 30 models have been densely benchmarked on a set of core scenarios and metrics under standardized conditions. Our evaluation surfaces 25 top-level findings concerning the interplay between different scenarios, metrics, and models. For full transparency, we release all raw model prompts and completions publicly for further analysis, as well as a general modular toolkit for easily adding new scenarios, models, metrics, and prompting strategies. We intend for HELM to be a living benchmark for the community, continuously updated with new scenarios, metrics, and models.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">liang-etal-2023-holistic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Holistic Evaluation of Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and Newman, Benjamin and Yuan, Binhang and Yan, Bobby and Zhang, Ce and Cosgrove, Christian Alexander and Manning, Christopher D and Re, Christopher and Acosta-Navas, Diana and Hudson, Drew Arad and Zelikman, Eric and Durmus, Esin and Ladhak, Faisal and Rong, Frieda and Ren, Hongyu and Yao, Huaxiu and WANG, Jue and Santhanam, Keshav and Orr, Laurel and Zheng, Lucia and Yuksekgonul, Mert and Suzgun, Mirac and Kim, Nathan and Guha, Neel and Chatterji, Niladri S. and Khattab, Omar and Henderson, Peter and Huang, Qian and Chi, Ryan Andrew and Xie, Sang Michael and Santurkar, Shibani and Ganguli, Surya and Hashimoto, Tatsunori and Icard, Thomas and Zhang, Tianyi and Chaudhary, Vishrav and Wang, William and Li, Xuechen and Mai, Yifan and Zhang, Yuhui and Koreeda, Yuta}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Transactions on Machine Learning Research}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2835-8856}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=iO4LZibEqW}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="tsunokake-etal-2023-predicting" class="col-sm-8"> <div class="title">Predicting Order Timing Utilizing Temporal Expressions in Sales Activity Reports</div> <div class="author"> Masaya Tsunokake, <em>Yuta Koreeda</em>, Ken Homma, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Teppei Inoue, Yuhei Niwa' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 37th Annual Conference of the Japanese Society for Artificial Intelligence</em>, May 2023 </div> <div class="periodical"> </div> <span class="rounded-pill badge publications-tag"> Domestic </span> <span class="rounded-pill badge publications-tag"> Japanese </span> <div class="links"> <a href="https://doi.org/10.11517/pjsai.JSAI2023.0_4Xin110" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://www.jstage.jst.go.jp/article/pjsai/JSAI2023/0/JSAI2023_4Xin110/_pdf/-char/ja" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="ja-entry btn btn-sm z-depth-0" role="button">Ja title</a> </div> <div class="ja-entry hidden d-print-inline"> <p></p> <p>角掛正弥, 是枝祐太, 本間健, 井上鉄平, 丹羽雄平. 2023. 営業報告書内の時間情報表現を手掛かりとした受注時期の予測. 人工知能学会全国大会論文集.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="miura-etal-2022-virtual" class="col-sm-8"> <div class="title">Virtual Shadow Drawing System Using Augmented Reality for Laparoscopic Surgery</div> <div class="author"> Satoshi Miura, Masaki Seki, <em>Yuta Koreeda</em>, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Yang Cao, Kazuya Kawamura, Yo Kobayashi, Masakatsu G. Fujie, Tomoyuki Miyashita' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>Advanced Biomedical Engineering</em>, Apr 2022 </div> <div class="periodical"> </div> <span class="rounded-pill badge publications-tag"> Journal </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.14326/abe.11.87" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://www.jstage.jst.go.jp/article/abe/11/0/11_11_87/_pdf/-char/ja" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Laparoscopic surgery holds great promise in medicine but remains challenging for surgeons because it is difficult to perceive depth while suturing. In addition to binocular parallax, such as three-dimensional vision, shadow is essential for depth perception. This paper presents an augmented reality system that draws virtual shadows to aid depth perception. On the visual display, the system generates shadows that mimic actual shadows by estimating shadow positions using image processing. The distance and angle between the forceps tip and the surface were estimated to evaluate the accuracy of the system. To validate the usefulness of this system in surgical applications, novices performed suturing tasks with and without the augmented reality system. The system error and delay were sufficiently small, and the generated shadows were similar to actual shadows. Furthermore, the suturing error decreased significantly when the augmented reality system was used. The shadow-drawing system developed in this study may help surgeons perceive depth during laparoscopic surgery.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="koreeda-manning-2021-contractnli-dataset" class="col-sm-8"> <div class="title">ContractNLI: A Dataset for Document-level Natural Language Inference for Contracts</div> <div class="author"> <em>Yuta Koreeda</em>, and Christopher Manning </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: EMNLP 2021</em>, Nov 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.18653/v1/2021.findings-emnlp.164" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2021.findings-emnlp.164.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://aclanthology.org/2021.findings-emnlp.164.mp4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Reviewing contracts is a time-consuming procedure that incurs large expenses to companies and social inequality to those who cannot afford it. In this work, we propose “document-level natural language inference (NLI) for contracts”, a novel, real-world application of NLI that addresses such problems. In this task, a system is given a set of hypotheses (such as “Some obligations of Agreement may survive termination.”) and a contract, and it is asked to classify whether each hypothesis is “entailed by”, “contradicting to” or “not mentioned by” (neutral to) the contract as well as identifying “evidence” for the decision as spans in the contract. We annotated and release the largest corpus to date consisting of 607 annotated contracts. We then show that existing models fail badly on our task and introduce a strong baseline, which (a) models evidence identification as multi-label classification over spans instead of trying to predict start and end tokens, and (b) employs more sophisticated context segmentation for dealing with long documents. We also show that linguistic characteristics of contracts, such as negations by exceptions, are contributing to the difficulty of this task and that there is much room for improvement.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">koreeda-manning-2021-contractnli-dataset</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{C}ontract{NLI}: A Dataset for Document-level Natural Language Inference for Contracts}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Koreeda, Yuta and Manning, Christopher}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: EMNLP 2021}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2021.findings-emnlp.164}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2021.findings-emnlp.164}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="koreeda-manning-2021-capturing" class="col-sm-8"> <div class="title">Capturing Logical Structure of Visually Structured Documents with Multimodal Transition Parser</div> <div class="author"> <em>Yuta Koreeda</em>, and Christopher Manning </div> <div class="periodical"> <em>In Proceedings of the Natural Legal Language Processing Workshop 2021</em>, Nov 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.18653/v1/2021.nllp-1.15" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2021.nllp-1.15.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>While many NLP pipelines assume raw, clean texts, many texts we encounter in the wild, including a vast majority of legal documents, are not so clean, with many of them being visually structured documents (VSDs) such as PDFs. Conventional preprocessing tools for VSDs mainly focused on word segmentation and coarse layout analysis, whereas fine-grained logical structure analysis (such as identifying paragraph boundaries and their hierarchies) of VSDs is underexplored. To that end, we proposed to formulate the task as prediction of “transition labels” between text fragments that maps the fragments to a tree, and developed a feature-based machine learning system that fuses visual, textual and semantic cues. Our system is easily customizable to different types of VSDs and it significantly outperformed baselines in identifying different structures in VSDs. For example, our system obtained a paragraph boundary detection F1 score of 0.953 which is significantly better than a popular PDF-to-text tool with an F1 score of 0.739.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">koreeda-manning-2021-capturing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Capturing Logical Structure of Visually Structured Documents with Multimodal Transition Parser}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Koreeda, Yuta and Manning, Christopher}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Natural Legal Language Processing Workshop 2021}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2021.nllp-1.15}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2021.nllp-1.15}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="morio-etal-2021-i-parser" class="col-sm-8"> <div class="title">i-Parser: Interactive Parser Development Kit for Natural Language Processing</div> <div class="author"> Gaku Morio, Hiroaki Ozaki, <em>Yuta Koreeda</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Terufumi Morishita, Toshinori Miyoshi' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI-21)</em>, Jan 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1609/aaai.v35i18.18021" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://cdn.aaai.org/ojs/18021/18021-13-21515-1-2-20210518.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>This demonstration paper presents i-Parser, a novel development kit that produces high-performance semantic parsers. i-Parser converts training graphs into sequences written in a context-free language, then our proposed model learns to generate the sequences. With interactive configuration and visualization, users can easily build their own parsers. Benchmark results of i-Parser showed high performances of various parsing tasks in natural language processing.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="ozaki-etal-2020-hitachi" class="col-sm-8"> <div class="title">Hitachi at MRP 2020: Text-to-Graph-Notation Transducer</div> <div class="author"> Hiroaki Ozaki, Gaku Morio, <em>Yuta Koreeda</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Terufumi Morishita, Toshinori Miyoshi' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing</em>, Nov 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.18653/v1/2020.conll-shared.4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/K19-2011.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>This paper presents our proposed parser for the shared task on Meaning Representation Parsing (MRP 2020) at CoNLL, where participant systems were required to parse five types of graphs in different languages. We propose to unify these tasks as a text-to-graph-notation transduction in which we convert an input text into a graph notation. To this end, we designed a novel Plain Graph Notation (PGN) that handles various graphs universally. Then, our parser predicts a PGN-based sequence by leveraging Transformers and biaffine attentions. Notably, our parser can handle any PGN-formatted graphs with fewer framework-specific modifications. As a result, ensemble versions of the parser tied for 1st place in both cross-framework and cross-lingual tracks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ozaki-etal-2020-hitachi</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hitachi at {MRP} 2020: Text-to-Graph-Notation Transducer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ozaki, Hiroaki and Morio, Gaku and Koreeda, Yuta and Morishita, Terufumi and Miyoshi, Toshinori}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2020.conll-shared.4}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2020.conll-shared.4}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="morio-etal-2020-towards" class="col-sm-8"> <div class="title">Towards Better Non-Tree Argument Mining: Proposition-Level Biaffine Parsing with Task-Specific Parameterization</div> <div class="author"> Gaku Morio, Hiroaki Ozaki, Terufumi Morishita, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Yuta Koreeda, Kohsuke Yanai' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL2020)</em>, Jul 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.18653/v1/2020.acl-main.298" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2020.acl-main.298.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="http://slideslive.com/38928683" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>State-of-the-art argument mining studies have advanced the techniques for predicting argument structures. However, the technology for capturing non-tree-structured arguments is still in its infancy. In this paper, we focus on non-tree argument mining with a neural model. We jointly predict proposition types and edges between propositions. Our proposed model incorporates (i) task-specific parameterization (TSP) that effectively encodes a sequence of propositions and (ii) a proposition-level biaffine attention (PLBA) that can predict a non-tree argument consisting of edges. Experimental results show that both TSP and PLBA boost edge prediction performance compared to baselines.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">morio-etal-2020-towards</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards Better Non-Tree Argument Mining: Proposition-Level Biaffine Parsing with Task-Specific Parameterization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morio, Gaku and Ozaki, Hiroaki and Morishita, Terufumi and Koreeda, Yuta and Yanai, Kohsuke}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL2020)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2020.acl-main.298}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2020.acl-main.298}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="ravikiran-etal-2020-hitachi" class="col-sm-8"> <div class="title">Hitachi at SemEval-2020 Task 12: Offensive Language Identification with Noisy Labels Using Statistical Sampling and Post-Processing</div> <div class="author"> Manikandan Ravikiran, Amin Ekant Muljibhai, Toshinori Miyoshi, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Hiroaki Ozaki, Yuta Koreeda, Sakata Masayuki' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the Fourteenth Workshop on Semantic Evaluation</em>, Dec 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.18653/v1/2020.semeval-1.258" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2020.semeval-1.258.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>In this paper, we present our participation in SemEval-2020 Task-12 Subtask-A (English Language) which focuses on offensive language identification from noisy labels. To this end, we developed a hybrid system with the BERT classifier trained with tweets selected using Statistical Sampling Algorithm (SA) and Post-Processed (PP) using an offensive wordlist. Our developed system achieved 34th position with Macro-averaged F1-score (Macro-F1) of 0.90913 over both offensive and non-offensive classes. We further show comprehensive results and error analysis to assist future research in offensive language identification with noisy labels.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ravikiran-etal-2020-hitachi</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hitachi at {S}em{E}val-2020 Task 12: Offensive Language Identification with Noisy Labels Using Statistical Sampling and Post-Processing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ravikiran, Manikandan and Muljibhai, Amin Ekant and Miyoshi, Toshinori and Ozaki, Hiroaki and Koreeda, Yuta and Masayuki, Sakata}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Fourteenth Workshop on Semantic Evaluation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2020.semeval-1.258}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2020.semeval-1.258}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="wang-etal-2020-split" class="col-sm-8"> <div class="title">Split First and Then Rephrase: Hierarchical Generation for Sentence Simplification</div> <div class="author"> Mengru Wang, Hiroaki Ozaki, <em>Yuta Koreeda</em>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Kohsuke Yanai' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of International Conference of the Pacific Association for Computational Linguistics (PACLING2019)</em>, Dec 2020 </div> <div class="periodical"> </div> <span class="rounded-pill badge publications-tag"> Award </span> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Awarded</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>The 16th International Conference of the Pacific Association for Computational Linguistics (PACLING) Best Paper Award</p> </div> <div class="abstract hidden"> <p>Split-and-rephrase is a strategy known to be used when humans need to break down a complex sentence into a meaning preserving sequence of shorter ones. Recent work proposed to model split-and-rephrase as a supervised sequence generation problem. However, different from other types of sequence generations, the task of split-and-rephrase inevitably introduces overlaps across splits to compensate for the missing context caused by separating a sentence. Serving as the baseline of this task, the vanilla SEQ2SEQ model usually suffers from inappropriate duplication because of the lack of a mechanism to plan how the source sentence should be split into shorter units. This work demonstrates that the problem of inappropriate duplication can be tackled by explicitly modeling the hierarchy within split-and-rephrase: Our model first introduces a separator network capable of selecting semantic components from the source sentence to form a representation for each split. Then, a decoder generates each split on the basis of its representation. Analyses demonstrate that with the aid of the separator, a model can effectively learn attention to avoid duplication and detect clues for splitting a sentence. Experimental results on the WikiSplit corpus show that our model outperforms the non-hierarchical SEQ2SEQ model by 1.4 points in terms of duplication rate and by 0.3 points in terms of coverage rate.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="miura-etal-2020-evaluation" class="col-sm-8"> <div class="title">Evaluation of Virtual Shadow’s Direction in Laparoscopic Surgery</div> <div class="author"> Satoshi Miura, Masaki Seki, <em>Yuta Koreeda</em>, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Yang Cao, Kazuya Kawamura, Yo Kobayashi, Masakatsu G. Fujie, Tomoyuki Miyashita' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>In 2020 8th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob)</em>, Nov 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/BioRob49111.2020.9224346" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Laparoscopic surgery can realize minimal invasive surgery. However, it’s difficult for surgeon to recognize the depth during suturing. Binocular endoscope helps surgeons to recognize the depth, but surgeons do not understand the circumstance by equipping with head mounted display. Since shadow helps surgeon to recognize the depth, in this paper, we developed the virtual shadow drawing system. The system shows shadow like actual by the estimation of the forceps position, surface shape and shadow’s position. We tested the accuracy of the system by evaluating the estimated distance and angle between the forceps and the surface. The error and delay were enough small to draw shadow like actual. Furthermore, participants performed the suturing task while looking at the shadow. The experiment was carried out in a variety of the shadow’s direction. As result, the suturing error’s mean and variance value was the least at the 270 deg. In conclusion, the appropriate shadow would be vertical to the wounds.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="koreeda-etal-2019-a" class="col-sm-8"> <div class="title">A Joint Neural Model for Patent Classification and Rationale Identification</div> <div class="author"> <em>Yuta Koreeda</em>, Hisao Mase, and Kohsuke Yanai </div> <div class="periodical"> <em>Transactions of the Japanese Society for Artificial Intelligence</em>, Nov 2019 </div> <div class="periodical"> </div> <span class="rounded-pill badge publications-tag"> Journal </span> <span class="rounded-pill badge publications-tag"> Japanese </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1527/tjsai.F-IC1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://www.jstage.jst.go.jp/article/tjsai/34/5/34_F-IC1/_pdf/-char/en" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="ja-entry btn btn-sm z-depth-0" role="button">Ja title</a> </div> <div class="abstract hidden"> <p>Japan Patent Office manually annotates submitted patents with F-terms (a patent classification scheme consisting of more than 300,000 labels) to aid search for prior patent applications. Keeping up the quality of F-term annotation is critical to patentability assessments, thus there is a demand for an automatic way to assist F-term annotation. One potential solution is to point out annotation mistakes by utilizing machine learning-based classification. However, the annotators cannot validate the predicted corrections because conventional classification methods do not give the rationales behind the corrections. Thus, the annotators may only adopt all or no corrections. The goal of this study was to assist F-term annotation by presenting annotators with corrections on the F-term annotation and the rationales behind the corrections. We proposed a joint neural model for F-term annotation and rationale identification. The proposed method incorporates a large portion of data annotated only with F-terms and a small portion of data annotated with rationales. It was first trained for F-term annotation, and then fine-tuned using the ground-truth rationales to discriminate rationales from non-rationales. We evaluated the proposed method on multiple F-terms from different technical domains. The proposed method outperformed baseline methods in terms of the rationale identification, implying that incorporating rationales in training is particularly useful in identifying rationales.</p> </div> <div class="ja-entry hidden d-print-inline"> <p></p> <p>是枝祐太, 間瀬久雄, 柳井孝介. 2019. 特許文献に対する分類付与と付与根拠箇所推定のための統合深層学習. 人工知能学会論文誌, 34:5, pages F-IC1_1-11.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yanai-etal-2017-struap" class="col-sm-8"> <div class="title">StruAP: A Tool for Bundling Linguistic Trees through Structure-based Abstract Pattern</div> <div class="author"> Kohsuke Yanai, Misa Sato, Toshihiko Yanase, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Kenzo Kurotsuchi, Yuta Koreeda, Yoshiki Niwa' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</em>, Sep 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.18653/v1/D17-2006" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/D17-2006.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>We present a tool for developing tree structure patterns that makes it easy to define the relations among textual phrases and create a search index for these newly defined relations. By using the proposed tool, users develop tree structure patterns through abstracting syntax trees. The tool features (1) intuitive pattern syntax, (2) unique functions such as recursive call of patterns and use of lexicon dictionaries, and (3) whole workflow support for relation development and validation. We report the current implementation of the tool and its effectiveness.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yanai-etal-2017-struap</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{S}tru{AP}: A Tool for Bundling Linguistic Trees through Structure-based Abstract Pattern}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yanai, Kohsuke and Sato, Misa and Yanase, Toshihiko and Kurotsuchi, Kenzo and Koreeda, Yuta and Niwa, Yoshiki}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/D17-2006}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/D17-2006}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="koreeda-etal-2017-bunji" class="col-sm-8"> <div class="title">bunji at SemEval-2017 Task 3: Combination of Neural Similarity Features and Comment Plausibility Features</div> <div class="author"> <em>Yuta Koreeda</em>, Takuya Hashito, Yoshiki Niwa, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Misa Sato, Toshihiko Yanase, Kenzo Kurotsuchi, Kohsuke Yanai' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</em>, Aug 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.18653/v1/S17-2058" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/S17-2058.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>This paper describes a text-ranking system developed by bunji team in SemEval-2017 Task 3: Community Question Answering, Subtask A and C. The goal of the task is to re-rank the comments in a question-and-answer forum such that useful comments for answering the question are ranked high. We proposed a method that combines neural similarity features and hand-crafted comment plausibility features, and we modeled inter-comments relationship using conditional random field. Our approach obtained the fifth place in the Subtask A and the second place in the Subtask C.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">koreeda-etal-2017-bunji</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{bunji at {S}em{E}val-2017 Task 3: Combination of Neural Similarity Features and Comment Plausibility Features}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Koreeda, Yuta and Hashito, Takuya and Niwa, Yoshiki and Sato, Misa and Yanase, Toshihiko and Kurotsuchi, Kenzo and Yanai, Kohsuke}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/S17-2058}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/S17-2058}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="sato-etal-2017-debating" class="col-sm-8"> <div class="title">Debating AI: Argument Generation by Retrieving Sentences from the Minutes of the Diet</div> <div class="author"> Misa Sato, Kohsuke Yanai, Toshihiko Yanase, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Yuta Koreeda, Yoshiki Niwa' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 31st Annual Conference of the Japanese Society for Artificial Intelligence</em>, May 2017 </div> <div class="periodical"> </div> <span class="rounded-pill badge publications-tag"> Award </span> <span class="rounded-pill badge publications-tag"> Japanese </span> <span class="rounded-pill badge publications-tag"> Domestic </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.11517/pjsai.JSAI2017.0_4Q19in2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://www.jstage.jst.go.jp/article/pjsai/JSAI2017/0/JSAI2017_4Q19in2/_pdf/-char/ja" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="ja-entry btn btn-sm z-depth-0" role="button">Ja title</a> </div> <div class="abstract hidden"> <p>We will demonstrate a counterargument generation system in debating, which aims to utilize newswire articles for decision-making support. Users can specify a claim such as “We should legalize casinos because they promote economy.” and then the system outputs counterargument scripts against the claim. </p> </div> <div class="ja-entry hidden d-print-inline"> <p></p> <p>佐藤美沙, 柳井孝介, 柳瀬利彦, 是枝祐太, 丹羽芳樹. 2017, 国会会議録を用いたディベート人工知能による意見生成. 2017年度人工知能学会全国大会論文集.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="koreeda-etal-2016-neural" class="col-sm-8"> <div class="title">Neural Attention Model for Classification of Sentences that Support Promoting/Suppressing Relationship</div> <div class="author"> <em>Yuta Koreeda</em>, Toshihiko Yanase, Kohsuke Yanai, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Misa Sato, Yoshiki Niwa' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the Third Workshop on Argument Mining (ArgMining2016)</em>, Aug 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.18653/v1/W16-2809" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/W16-2809.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">koreeda-etal-2016-neural</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neural Attention Model for Classification of Sentences that Support Promoting/Suppressing Relationship}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Koreeda, Yuta and Yanase, Toshihiko and Yanai, Kohsuke and Sato, Misa and Niwa, Yoshiki}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Third Workshop on Argument Mining ({A}rg{M}ining2016)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/W16-2809}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/W16-2809}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="koreeda-etal-2016-virtually" class="col-sm-8"> <div class="title">Virtually transparent surgical instruments in endoscopic surgery with augmentation of obscured regions</div> <div class="author"> <em>Yuta Koreeda</em>, Yo Kobayashi, Satoshi Ieiri, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Yuya Nishio, Kazuya Kawamura, Satoshi Obata, Ryota Souzaki, Makoto Hashizume, Masakatsu G. Fujie' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>International Journal of Computer Assisted Radiology and Surgery</em>, Oct 2016 </div> <div class="periodical"> </div> <span class="rounded-pill badge publications-tag"> Journal </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s11548-016-1384-5" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/content/pdf/10.1007/s11548-014-1083-z.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>We developed and evaluated a visual compensation system that allows surgeons to visualize obscured regions in real time, such that the surgical instrument appears virtually transparent.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">koreeda-etal-2016-virtually</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Koreeda, Yuta and Kobayashi, Yo and Ieiri, Satoshi and Nishio, Yuya and Kawamura, Kazuya and Obata, Satoshi and Souzaki, Ryota and Hashizume, Makoto and Fujie, Masakatsu G.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Virtually transparent surgical instruments in endoscopic surgery with augmentation of obscured regions}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Journal of Computer Assisted Radiology and Surgery}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1927-1936}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1861-6429}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s11548-016-1384-5}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s11548-016-1384-5}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="sato-etal-2016-textual" class="col-sm-8"> <div class="title">Textual Supportiveness Recognition Based on Combinations of Syntax Features for Automated Argument Generation</div> <div class="author"> Misa Sato, Kohsuke Yanai, Toshihiko Yanase, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Toshinori Miyoshi, Yuta Koreeda, Yoshiki Niwa' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Transactions of the Japanese Society for Artificial Intelligence</em>, Oct 2016 </div> <div class="periodical"> </div> <span class="rounded-pill badge publications-tag"> Journal </span> <span class="rounded-pill badge publications-tag"> Japanese </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1527/tjsai.AI30-L" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="ja-entry btn btn-sm z-depth-0" role="button">Ja title</a> </div> <div class="abstract hidden"> <p>This paper describes a technique to recognize "supportiveness" of a given text for an argument topic object and a value. Given an argument topic object (o), a value (v), and a text fragment (t), supportiveness refers to whether t supports a hypothesis "o promotes/suppresses v" or not. For example, with "o: casino" and "v: employment", then a text "The casinos in Mississippi have created 35,000 jobs." should support a hypothesis "o promotes v". This technique enables to automatically collect texts representing reasons and counterexamples for some hypothesis that humans build up (e.g. "casino promotes employment"), combined with text search. Because the difference from relation extraction is polarity of relations, proposed method utilizes multiplifications based on local syntax structures, extending reversing hypothesis in sentiment analysis. We propose feature combinations consisting of "primary features" and "secondary features" for supportiveness recognition. "Primary features" represent local syntax structures around a given target or a given value. "Secondary features" represent global syntax structures generated by combining the primary features. The proposed method calculates weighted sum of secondary features to recognize promoting/suppressing supportiveness. The experiments showed that our method outperforms a Bag-of-Words baseline and a conventional relation extraction method.</p> </div> <div class="ja-entry hidden d-print-inline"> <p></p> <p>佐藤美沙, 柳井孝介, 柳瀬利彦, 三好利昇, 是枝祐太, 丹羽芳樹. 2016. 意見文章自動生成のための組合せ構文特徴を用いたサポート性推定. 人工知能学会論文誌, 31:6, pages AI30-L_1-12.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="koreeda-etal-2015-development" class="col-sm-8"> <div class="title">Development and testing of an endoscopic pseudo-viewpoint alternating system</div> <div class="author"> <em>Yuta Koreeda</em>, Satoshi Obata, Yuya Nishio, and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Satoshi Miura, Yo Kobayashi, Kazuya Kawamura, Ryota Souzaki, Satoshi Ieiri, Makoto Hashizume, Masakatsu G. Fujie' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </div> <div class="periodical"> <em>International Journal of Computer Assisted Radiology and Surgery</em>, May 2015 </div> <div class="periodical"> </div> <span class="rounded-pill badge publications-tag"> Journal </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s11548-014-1083-z" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/content/pdf/10.1007/s11548-014-1083-z.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>An endoscopic system is needed that presents informative images irrespective of the surgical situation and the number of degrees of freedom in endoscopic manipulation. This goal may be achieved with a virtual reality view for a region of interest from an arbitrary viewpoint. An endoscopic pseudo-viewpoint alternation system for this purpose was developed and tested.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">koreeda-etal-2015-development</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Koreeda, Yuta and Obata, Satoshi and Nishio, Yuya and Miura, Satoshi and Kobayashi, Yo and Kawamura, Kazuya and Souzaki, Ryota and Ieiri, Satoshi and Hashizume, Makoto and Fujie, Masakatsu G.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Development and testing of an endoscopic pseudo-viewpoint alternating system}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Journal of Computer Assisted Radiology and Surgery}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{619-628}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1861-6429}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s11548-014-1083-z}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s11548-014-1083-z}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="nakayama-etal-2015-estimation" class="col-sm-8"> <div class="title">Estimation technique of the destined target with gesture recognition for the development of in-car interface of automated driving vehicle</div> <div class="author"> Masayuki Nakayama, Satoshi Miura, Shinya Kawano, and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Yuta Koreeda, Akihiro Yamamoto, Ryota Fukumoto, Tsuyoshi Sakuma, Tsuyoshi Nakashima, Yo Kobayashi, Masakatsu G. Fujie' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </div> <div class="periodical"> <em>Transactions of the JSME</em>, Dec 2015 </div> <div class="periodical"> </div> <span class="rounded-pill badge publications-tag"> Journal </span> <span class="rounded-pill badge publications-tag"> Japanese </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1299/transjsme.15-00088" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://www.jstage.jst.go.jp/article/transjsme/81/832/81_15-00088/_pdf/-char/ja" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="ja-entry btn btn-sm z-depth-0" role="button">Ja title</a> </div> <div class="abstract hidden"> <p>In recent years, development of the automated driving system is aggressively promoted for the purpose of reducing burden of drivers and for the enhanced safety. Transferring the intention of the driver to the automobile control, such as to stop on the way or to change destinations, is essential even if a direct control from the driver is no longer necessary. Therefore, an in-car interface to conduct intention of the driver promptly and accurately to the automobile control is needed. In this paper, we proposed an interface which recognizes the intended target of the driver using gestures and speech recognition. The speech recognition technology was previously developed. Hence, we developed an interface to recognize the direction in which the driver is pointing toward from the gesture. We hypothesize that we can estimate the direction in which the driver is pointing toward from the fingertip and eye position. Verification using three-dimensional motion analysis system showed that it is possible to recognize the direction of the object with a maximum error of 5.5° and an average error of 1.2°. After verifying the hypothesis, a position measurement device that integrates Leap Motion® and KINECT®, the non-contact sensor, was developed to recognize gestures of the driver in the automobiles. The maximum error of the angle recognition in accordance with the present device was 16.1°. However, the value of the error exists only in a certain interval. For this reason, by taking into account the movement of the eye position, and provide adequate tuning for each driver, proposed interface is sufficiently usable.</p> </div> <div class="ja-entry hidden d-print-inline"> <p></p> <p>中山正之, 三浦智, 河野信哉, 是枝祐太, 山本晃裕, 福本亮太, 佐久間壮, 中島康貴, 小林洋, 藤江正克. 2015. 自動運転のインターフェース構築を目的とした視点と指先位置の測定による指示方向推定手法の構築. 日本機械学会論文集, 81:832, pages 15-00088-15-00088.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Yuta Koreeda. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?d2bbd98a1d927c7b9ae2aa5255ea3647"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6B%6F%72%65%79%6F%75[%61%74]%6D%61%63.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-ieee-xplore",title:"IEEE Xplore",section:"Socials",handler:()=>{window.open("https://ieeexplore.ieee.org/author/37088534314/","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/koreyou","_blank")}},{id:"socials-dblp",title:"DBLP",section:"Socials",handler:()=>{window.open("https://dblp.org/pid/185/5509.html","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>